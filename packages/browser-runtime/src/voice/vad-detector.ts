/**
 * VAD (Voice Activity Detection) Detector
 * ä½¿ç”¨ @ricky0123/vad-web è¿›è¡Œè¯­éŸ³æ´»åŠ¨æ£€æµ‹
 */

import { MicVAD } from "@ricky0123/vad-web";

export interface VADConfig {
  positiveSpeechThreshold?: number;
  negativeSpeechThreshold?: number;
  minSpeechFrames?: number;
  preSpeechPadFrames?: number;
  redemptionFrames?: number;
  onSpeechStart?: () => void;
  onSpeechEnd?: (audio: Float32Array) => void;
  onVADMisfire?: () => void;
  onVolumeChange?: (volume: number) => void;
}

export class VADDetector {
  private vad: MicVAD | null = null;
  private audioContext: AudioContext | null = null;
  private analyser: AnalyserNode | null = null;
  private microphone: MediaStreamAudioSourceNode | null = null;
  private volumeCheckInterval: number | null = null;
  private isRunning = false;
  private config: VADConfig;

  constructor(config: VADConfig = {}) {
    this.config = {
      positiveSpeechThreshold: 0.8,
      negativeSpeechThreshold: 0.5,
      minSpeechFrames: 5,
      preSpeechPadFrames: 10,
      redemptionFrames: 20,
      ...config,
    };
  }

  /**
   * åˆå§‹åŒ–å¹¶å¯åŠ¨ VAD
   */
  async start(): Promise<void> {
    if (this.isRunning) {
      console.warn("[VAD] Already running");
      return;
    }

    try {
      console.log("[VAD] Requesting microphone access...");

      // è¯·æ±‚éº¦å…‹é£æƒé™
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
        },
      });

      // åˆ›å»º AudioContext ç”¨äºéŸ³é‡æ£€æµ‹
      this.audioContext = new AudioContext();
      this.analyser = this.audioContext.createAnalyser();
      this.analyser.fftSize = 256;
      this.microphone = this.audioContext.createMediaStreamSource(stream);
      this.microphone.connect(this.analyser);

      // å¯åŠ¨éŸ³é‡æ£€æµ‹
      this.startVolumeMonitoring();

      console.log("[VAD] Initializing VAD...");

      // åˆå§‹åŒ– VAD
      console.log("[VAD] Initializing with assets:", {
        base: chrome.runtime.getURL("assets/vad/"),
        onnx: chrome.runtime.getURL("assets/onnx/"),
      });

      // éªŒè¯èµ„æºæ˜¯å¦å¯è®¿é—®
      try {
        const modelUrl = chrome.runtime.getURL(
          "assets/vad/silero_vad_legacy.onnx",
        );
        const wasmUrl = chrome.runtime.getURL("assets/onnx/ort-wasm-simd.wasm");
        const wasmThreadedUrl = chrome.runtime.getURL(
          "assets/onnx/ort-wasm-simd-threaded.wasm",
        );

        console.log("[VAD] Checking resources accessibility...");

        const [modelResp, wasmResp, wasmThreadedResp] = await Promise.all([
          fetch(modelUrl, { method: "HEAD" }),
          fetch(wasmUrl, { method: "HEAD" }),
          fetch(wasmThreadedUrl, { method: "HEAD" }),
        ]);

        console.log("[VAD] Resources check:", {
          model: modelResp.ok,
          wasm: wasmResp.ok,
          wasmThreaded: wasmThreadedResp.ok,
          modelStatus: modelResp.status,
          wasmStatus: wasmResp.status,
          wasmThreadedStatus: wasmThreadedResp.status,
        });
      } catch (e) {
        console.warn("[VAD] Resource check failed:", e);
      }

      // è®¾ç½® onnxruntime-web çš„è·¯å¾„
      // @ts-expect-error - MicVAD å†…éƒ¨ä½¿ç”¨ ort
      if (window.ort) {
        // @ts-expect-error
        window.ort.env.wasm.wasmPaths = chrome.runtime.getURL("assets/onnx/");
        // å¼ºåˆ¶ä½¿ç”¨å•çº¿ç¨‹ï¼Œé¿å… threaded WASM åŠ è½½é—®é¢˜å’Œ SharedArrayBuffer å…¼å®¹æ€§é—®é¢˜
        // @ts-expect-error
        window.ort.env.wasm.numThreads = 1;

        // ç¦ç”¨ eval çš„ä½¿ç”¨ (onnxruntime-web å¯èƒ½ä¼šå°è¯•ä½¿ç”¨ new Function)
        // @ts-expect-error
        window.ort.env.wasm.proxy = false;
      }

      this.vad = await MicVAD.new({
        baseAssetPath: chrome.runtime.getURL("assets/vad/"),
        onnxWASMBasePath: chrome.runtime.getURL("assets/onnx/"),
        positiveSpeechThreshold: this.config.positiveSpeechThreshold!,
        negativeSpeechThreshold: this.config.negativeSpeechThreshold!,
        minSpeechFrames: this.config.minSpeechFrames!,
        preSpeechPadFrames: this.config.preSpeechPadFrames!,
        redemptionFrames: this.config.redemptionFrames!,
        onSpeechStart: () => {
          console.log("[VAD] Speech started");
          this.config.onSpeechStart?.();
        },
        onSpeechEnd: (audio) => {
          console.log("[VAD] Speech ended, audio length:", audio.length);
          this.config.onSpeechEnd?.(audio);
        },
        onVADMisfire: () => {
          console.log("[VAD] Misfire detected");
          this.config.onVADMisfire?.();
        },
      });

      this.vad.start();
      this.isRunning = true;
      console.log("[VAD] Started successfully");
    } catch (error) {
      console.error("[VAD] Failed to start:", error);
      this.cleanup();
      throw error;
    }
  }

  /**
   * åœæ­¢ VAD
   */
  async stop(): Promise<void> {
    if (!this.isRunning) {
      console.log("[VAD] Already stopped, skipping");
      return;
    }

    console.log("[VAD] ğŸ›‘ Stopping VAD...");

    // ç«‹å³æ ‡è®°ä¸ºéè¿è¡ŒçŠ¶æ€
    this.isRunning = false;

    // åœæ­¢éŸ³é‡ç›‘æµ‹
    this.stopVolumeMonitoring();

    // åœæ­¢VAD
    if (this.vad) {
      console.log("[VAD] Pausing MicVAD...");
      this.vad.pause();
      this.vad = null;
    }

    // æ¸…ç†éŸ³é¢‘èµ„æº
    this.cleanup();

    console.log("[VAD] âœ… VAD stopped completely");
  }

  /**
   * æš‚åœ VADï¼ˆä½†ä¸é‡Šæ”¾èµ„æºï¼‰
   */
  pause(): void {
    if (this.vad && this.isRunning) {
      this.vad.pause();
      this.stopVolumeMonitoring();
      console.log("[VAD] Paused");
    }
  }

  /**
   * æ¢å¤ VAD
   */
  resume(): void {
    if (this.vad && this.isRunning) {
      this.vad.start();
      this.startVolumeMonitoring();
      console.log("[VAD] Resumed");
    }
  }

  /**
   * å¯åŠ¨éŸ³é‡ç›‘æµ‹
   */
  private startVolumeMonitoring(): void {
    if (!this.analyser || this.volumeCheckInterval !== null) {
      return;
    }

    const bufferLength = this.analyser.frequencyBinCount;
    const dataArray = new Uint8Array(bufferLength);

    const checkVolume = () => {
      if (!this.analyser) return;

      this.analyser.getByteFrequencyData(dataArray);

      // è®¡ç®—å¹³å‡éŸ³é‡
      let sum = 0;
      for (let i = 0; i < bufferLength; i++) {
        sum += dataArray[i] || 0;
      }
      const average = sum / bufferLength;

      // å½’ä¸€åŒ–åˆ° 0-1
      const volume = average / 255;

      this.config.onVolumeChange?.(volume);
    };

    // æ¯ 50ms æ£€æŸ¥ä¸€æ¬¡éŸ³é‡
    this.volumeCheckInterval = window.setInterval(checkVolume, 50);
  }

  /**
   * åœæ­¢éŸ³é‡ç›‘æµ‹
   */
  private stopVolumeMonitoring(): void {
    if (this.volumeCheckInterval !== null) {
      clearInterval(this.volumeCheckInterval);
      this.volumeCheckInterval = null;
    }
  }

  /**
   * æ¸…ç†èµ„æº
   */
  private cleanup(): void {
    if (this.microphone) {
      this.microphone.disconnect();
      this.microphone = null;
    }

    if (this.analyser) {
      this.analyser.disconnect();
      this.analyser = null;
    }

    if (this.audioContext) {
      this.audioContext.close();
      this.audioContext = null;
    }
  }

  /**
   * æ£€æŸ¥æ˜¯å¦æ­£åœ¨è¿è¡Œ
   */
  isActive(): boolean {
    return this.isRunning;
  }
}
